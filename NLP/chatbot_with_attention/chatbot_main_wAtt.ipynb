{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import string\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#upload dictionaries\n",
    "\n",
    "with open('dict_w2i_chatbot.json') as json_file: \n",
    "    dict_w2i = json.load(json_file) \n",
    "\n",
    "with open('dict_i2w_chatbot.json') as json_file: \n",
    "    dict_i2w = json.load(json_file) \n",
    "\n",
    "with open('contractions_dict.json') as json_file: \n",
    "    contractions_dict = json.load(json_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define variables\n",
    "lat_dim=512\n",
    "vocab_len=len(dict_w2i)-3\n",
    "batch_size=64\n",
    "maximum_iterations=10\n",
    "buck_t1=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create models\n",
    "import chatbot_models_class as cb\n",
    "\n",
    "\n",
    "encoder_=cb.encoder_model(lat_dim=lat_dim,vocab_len=vocab_len)\n",
    "decoder_=cb.decoder_model(lat_dim=lat_dim,batch_size=batch_size,vocab_len=vocab_len,buck_t1=buck_t1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f85efdc8e80>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load weights\n",
    "\n",
    "encoder_.load_weights(\"models_Att/encoder_att_weights_inv_input\")\n",
    "decoder_.load_weights(\"models_Att/decoder_att_weights_inv_input\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing input string\n",
    "def exp_remPunt(sent):\n",
    "    '''\n",
    "    clean the input sentence\n",
    "    - set to lower\n",
    "    - remove contract form\n",
    "    - remove punctuation\n",
    "    '''\n",
    "    clean_sent=[]\n",
    "    table = str.maketrans(dict.fromkeys(string.punctuation))\n",
    "    remove_digits = str.maketrans('', '', string.digits)\n",
    "    sent=sent.lower()\n",
    "    \n",
    "    for word in sent.split():\n",
    "        if word in contractions_dict:\n",
    "            sent = sent.replace(word, contractions_dict[word])  #expand\n",
    "\n",
    "    sent = sent.translate(remove_digits)\n",
    "    clean_sent.append(sent.translate(table).lower()) #remove punt and set to lower\n",
    "    \n",
    "    return clean_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_seq(l_sent):\n",
    "    '''\n",
    "    input list string \n",
    "    '''\n",
    "    emb_str=[]\n",
    "    for l in l_sent:\n",
    "        for word in l.split():\n",
    "            if (word in dict_w2i):\n",
    "                emb_str.append(dict_w2i[word])\n",
    "\n",
    "   \n",
    "    emb_str = pad_sequences([emb_str],buck_t1, padding='post')\n",
    "    #return np.flip(emb_str)  #reverse and return\n",
    "    return emb_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_loop(sentence): \n",
    "    \n",
    "    sentence=exp_remPunt(sentence)\n",
    "    sentence=string_to_seq(sentence)\n",
    "    sent_tens= tf.convert_to_tensor(sentence) \n",
    "    encoder_embedding=encoder_.encoder_embedding_layer(sent_tens)\n",
    "    encoder_output,enc_state_h,enc_state_c =encoder_.encoder(encoder_embedding,\n",
    "                                                            initial_state=[tf.zeros((1, lat_dim*2)), tf.zeros((1, lat_dim*2))])\n",
    "\n",
    "    dec_infere_inp = tf.expand_dims([ dict_w2i['<sos>']],1)\n",
    "    decoder_embedding=decoder_.decoder_embedding_layer(dec_infere_inp)#!!\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    inference_sampler=tfa.seq2seq.sampler.GreedyEmbeddingSampler()#(self.decoder_embedding_layer)\n",
    "\n",
    "    #inference decoder\n",
    "    inference_decoder=tfa.seq2seq.BasicDecoder(cell=decoder_.attention_decoder,\n",
    "                                               sampler=inference_sampler,\n",
    "                                               output_layer=decoder_.dense_layer,\n",
    "                                               maximum_iterations=maximum_iterations\n",
    "                                              )\n",
    "\n",
    "\n",
    "    #setup memory \n",
    "    decoder_.attention_mechanism.setup_memory(encoder_output)\n",
    "\n",
    "\n",
    "    start_tokens=tf.fill([1], dict_w2i['<sos>'])\n",
    "\n",
    "    decoder_embedding_matrix = decoder_.decoder_embedding_layer.variables[0] \n",
    "    _,inputs_t0,states_t0=inference_decoder.initialize(decoder_embedding_matrix,\n",
    "                                       initial_state=decoder_.get_initial_states(batch_size=1,\n",
    "                                                                                 enc_state_h=enc_state_h,\n",
    "                                                                                 enc_state_c=enc_state_c),\n",
    "                                       start_tokens=start_tokens,\n",
    "                                       end_token=dict_w2i['<eos>'],\n",
    "                                       )\n",
    "\n",
    "    #init \"inference iterators\"\n",
    "    input_iterator=inputs_t0\n",
    "    state_iterator=states_t0  \n",
    "    predictions=np.empty((1,0),dtype=np.int32) \n",
    "\n",
    "    #prediction loop\n",
    "    stop_condition=False\n",
    "    iteration_counter=0\n",
    "    while not stop_condition:\n",
    "\n",
    "        outputs,states_tn, inputs_tn, finished = inference_decoder.step(iteration_counter,input_iterator,state_iterator)\n",
    "        iteration_counter+=1\n",
    "\n",
    "        input_iterator = inputs_tn\n",
    "        state_iterator = states_tn\n",
    "        predictions = np.append(predictions, outputs.sample_id)\n",
    "\n",
    "        if iteration_counter>=maximum_iterations:\n",
    "            stop_condition=True\n",
    "\n",
    "        if outputs.sample_id==dict_w2i['<eos>']:\n",
    "            stop_condition=True\n",
    "            predictions=predictions[:-1]\n",
    "            \n",
    "    bot_s=\"BOT:\"\n",
    "    for i in predictions:\n",
    "        bot_s=bot_s+\" \" +dict_i2w[str(i)]\n",
    "    print(bot_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type \"quitbot\" to exit. Let's start! \n",
      " \n",
      "\n",
      "YOU: hello there\n",
      "BOT: hello\n",
      "YOU: how are you?\n",
      "BOT: i am fine\n",
      "YOU: tell me something\n",
      "BOT: i love you\n",
      "YOU: good night\n",
      "BOT: good night\n",
      "YOU: quitbot\n",
      "BOT: good bye\n"
     ]
    }
   ],
   "source": [
    "print(\"Type \\\"quitbot\\\" to exit. Let\\'s start! \\n \\n\")\n",
    "stop_condition=False\n",
    "\n",
    "while not stop_condition:\n",
    "    sentence = input(\"YOU: \")\n",
    "    if sentence=='quitbot':\n",
    "        print(\"BOT: good bye\")\n",
    "        stop_condition=True\n",
    "        continue\n",
    "    chat_loop(sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
